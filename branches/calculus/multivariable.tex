\section{Multivariable Calculus}

$\vector{f}: X \subseteq \mathbb{R}^n \rightarrow \mathbb{R}^m$ \\
$f: X \subseteq \mathbb{R}^n \rightarrow \mathbb{R}$

\subsection{Partial Derivatives}
	\begin{equation}
		\partialDerivative{f}{x_i} = \lim_{h \rightarrow 0} \frac{f(x_1, ..., x_i + h, ..., x_n) - f(x_1, ..., x_n)}{h}
	\end{equation}
	\begin{itemize}
		\item Gradient
			\begin{equation}
				\gradient f = (f_{x_1} ,\; ... ,\; f_{x_n}) \\
				\gradient f(\vector{a}) = (f_{x_1}(\vector{a}) ,\; ... ,\; f_{x_n}(\vector{a}))
			\end{equation}
		\item Derivative matrix
			\begin{equation}
				D\vector{f} = \begin{bmatrix}
					\partialDerivative{f_1}{x_1} & \dots  & \partialDerivative{f_1}{x_n} \\
					\vdots                       & \ddots & \vdots                       \\
					\partialDerivative{f_m}{x_1} & \dots  & \partialDerivative{f_m}{x_n} \\
				\end{bmatrix} \qquad D\vector{f}(\vector{a}) = \begin{bmatrix}
					\partialDerivative{f_1}{x_1}(\vector{a}) & \dots  & \partialDerivative{f_1}{x_n}(\vector{a}) \\
					\vdots                       & \ddots & \vdots                       \\
					\partialDerivative{f_m}{x_1}(\vector{a}) & \dots  & \partialDerivative{f_m}{x_n}(\vector{a}) \\
				\end{bmatrix}
			\end{equation}
		\item Tangent plane
			\begin{equation}
				z = h(x, y) = f(a,b) + f_x(a,b) (x-a) + f_y(a,b) (y-b) \\
				f_x(x_0, y_0, z_0)(x-x_0) + f_y(x_0, y_0, z_0)(y-y_0) + f_z(x_0, y_0, z_0)(z-z_0) = 0
			\end{equation}
			\begin{itemize}
				\item Normal vector
					\begin{equation}
						\vector{n} = -f_x(a,b) \vectorUnit{i} -f_y(a,b) \vectorUnit{j} + \vectorUnit{k} = (-f_x(a,b), -f_y(a,b), 1)
					\end{equation}
				\item Hyperplane
					\begin{equation}
							\vector{h}(\vector{x}) = \vector{f}(\vector{a}) + D\vector{f}(\vector{a}) (\vector{x} - \vector{a}) \\
							\gradient f(\vector{x}_0) \cdot (\vector{x} - \vector{x}_0) = 0
					\end{equation}
			\end{itemize}
		\item Differentiability
			\begin{enumerate}
				\item $D\vector{f}(\vector{a})$ exists
				\item \begin{equation}
					\lim_{\vector{x} \tends \vector{a}} \frac{\vector{f}(\vector{x}) - \vector{h}(\vector{x})}{\magnitude{\vector{x} - \vector{a}}} = 0
				\end{equation}
			\end{enumerate}
		\item Higher-order partial derivative
			\begin{equation}
				\frac{\partial^k f}{\partial x_{i_k} \dots \partial x_{i_1}} = \partialDerivative{}{x_{i_k}} \dots \partialDerivative{}{x_{i_1}} f(x_1, \dots, x_n)
			\end{equation}
			\begin{itemize}
				\item Clairautâ€™s Theorem
					\begin{equation}
						\frac{\partial^k f}{\partial x_{i_k} \dots \partial x_{i_1}} = \frac{\partial^k f}{\partial x_{j_1} \dots \partial x_{j_k}}
					\end{equation}
			\end{itemize}
		\item Chain rule
			\begin{equation}
				D(\vector{f} \circ \vector{x})(\vector{t}_0) = D\vector{f}(\vector{x}_0) D\vector{x}(\vector{t}_0) \\
				(f \circ \vector{x})'(\vector{t}_0) = \gradient f(\vector{x}) \dotProduct \vector{x}'(t)
			\end{equation}
		\item Directional derivative
			\begin{equation}
				D_{\vectorUnit{u}} f(\vector{a}) = \gradient f(\vector{a}) \dotProduct \vectorUnit{u} = \magnitude{\gradient f(\vector{a})} \cos \theta
			\end{equation}
	\end{itemize}
\subsection{Vector-valued Functions}
	\begin{itemize}
		\item Arclength
		\item Vector fields
		\item Del operator
			\begin{equation}
				\nabla = \left( \partialDerivative{}{x_1} ,\; \partialDerivative{}{x_2} ,\; \dots ,\; \partialDerivative{}{x_n} \right)
			\end{equation}
		\item Gradient
			\begin{equation}
				\nabla f = \left( \partialDerivative{f}{x_1} ,\; \partialDerivative{f}{x_2} ,\; \dots ,\; \partialDerivative{f}{x_n} \right)
			\end{equation}
		\item Divergence
			\begin{equation}
				\nabla \dotProduct \vector{F} = \partialDerivative{f}{x_1} + \partialDerivative{f}{x_2} + \dots + \partialDerivative{f}{x_n}
			\end{equation}
		\item Curl
			\begin{equation}
				\nabla \crossProduct \vector{F} = \begin{vmatrix}
					\vectorUnit{i}          & \vectorUnit{j}          & \vectorUnit{k}          \\
					\partialDerivative{}{x} & \partialDerivative{}{y} & \partialDerivative{}{z} \\
					F_1                     & F_2                     & F_3
				\end{vmatrix}
			\end{equation}
		\item Theorems
			\begin{enumerate}
				\item If $f$ is a scalar-valued function of class $C^2$, then
					\begin{equation}
						\nabla \crossProduct (\nabla f) = \vector{0}
					\end{equation}
				\item If $\vector{F}$ is a vector-valued function of class $C^2$ on $X \subseteq \mathbb{R}^3$, then
					\begin{equation}
						\nabla \dotProduct (\nabla \crossProduct \vector{F}) = 0
					\end{equation}
			\end{enumerate}
	\end{itemize}
\subsection{Maxima and Minima}
	\begin{itemize}
		\item Taylor Polynomials
			% 11:02
			\begin{itemize}
				\item First-order
					\begin{equation}
						p_1(\vector{x}) = f(\vector{a}) + \sum_{i=1}^n f_{x_i}(\vector{a}) (x_i - a_i) \\
						p_1(\vector{x}) = f(\vector{a}) + Df(\vector{a}) (\vector{x}) - \vector{a})
					\end{equation}
				\item Second-order
					\begin{equation}
						p_2(\vector{x}) = f(\vector{a}) + \sum_{i=1}^n f_{x_i}(\vector{a}) (x_i - a_i) + \frac{1}{2} \sum_{i,j=1}^n f_{x_ix_j}(\vector{a}) (x_i - a_i)(x_j - a_j)
					\end{equation}
			\end{itemize}
		\item Hessian Criterion
			\begin{itemize}
				\item Hessian matrix
					\begin{equation}
						Hf(\vector{a}) = \begin{bmatrix}
							f_{x_1x_1(\vector{a})} & \dots  & f_{x_1x_n(\vector{a})} \\
							\vdots                 & \ddots & \vdots                 \\
							f_{x_nx_1(\vector{a})} & \dots  & f_{x_nx_n(\vector{a})} \\
						\end{bmatrix}
					\end{equation}
				\item Principal minor
					\begin{equation}
						d_k = \textrm{determinant of  the upperleftmost } k \times k \textrm{ submatrix of } Hf(\vector{a})
					\end{equation}
			\end{itemize}
			\begin{enumerate}
				\item If all $d_k > 0$, then the critical point $\vector{a}$ gives a local minimum.
				\item If $d_1 < 0 ,\; d_2 > 0 ,\; d_3 < 0 ,\; \dots$, then the critical point $\vector{a}$ gives a local maximum.
				\item If neither case 1 nor case 2 occurs, then $\vector{a}$ is a saddle point.
			\end{enumerate}
	\end{itemize}